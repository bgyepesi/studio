{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Plot Images\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import math\n",
    "plt.style.use('ggplot')\n",
    "import matplotlib\n",
    "# Set GPU usage\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "# Plotly \n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/anirudh/github/aip-eval\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from studio.evaluation.keras import metrics, utils, visualizer\n",
    "from studio.evaluation.keras.evaluators import CNNEvaluator\n",
    "from studio.evaluation.keras.evaluators import Evaluator\n",
    "from studio.evaluation.keras.evaluators import SequentialCNNEvaluator\n",
    "from studio.evaluation.keras.evaluators import VisualQAEvaluator\n",
    "from visual_qa.visual_qa import VisualQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_dir = 'mini_evaluation/'\n",
    "model_path = '/data/models/133_way_april_2019/ensemble/xception/model_max_acc_1gpu.h5'\n",
    "visual_dictionary = '/home/anirudh/github/qa-data/data/visual_classifier/133_way_min_150_images_april_2019_model_map_diagnosis_nodes.json'\n",
    "by_definition_csv = '/home/anirudh/github/qa-data/data/by-definition/custom_by_definition_katrina.csv'\n",
    "qa_data_json = '/home/anirudh/github/qa-data/data/testset/survey_testset_derm_18july19.json'\n",
    "valid_evidence = '/home/anirudh/github/qa-data/data/by-definition/valid_evidence.json'\n",
    "visual_data_dir = '/data/datasets/visual_qa/new_cases'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/anirudh/github/aip-eval/.venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anirudh/github/aip-eval/.venv/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning:\n",
      "\n",
      "No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnn_evaluator = CNNEvaluator(\n",
    "        concept_dictionary_path=None,\n",
    "        custom_objects=None,\n",
    "        concepts=None,\n",
    "        model_path=model_path,\n",
    "        batch_size=32,\n",
    "        verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_qa_evaluator = VisualQAEvaluator(\n",
    "    report_dir=report_dir,\n",
    "    qa_data_json = qa_data_json,\n",
    "    visual_dictionary = visual_dictionary,\n",
    "    by_definition_csv = by_definition_csv,\n",
    "    valid_evidence = valid_evidence\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_diagnosis_ids = ['AIP:0022217',\n",
    " 'AIP:0000942',\n",
    " 'AIP:0001341',\n",
    " 'AIP:0100003',\n",
    " 'AIP:0002471',\n",
    " 'AIP:0000461',\n",
    " 'AIP:0001398',\n",
    " 'AIP:0100004',\n",
    " 'AIP:0003513',\n",
    " 'AIP:0002367',\n",
    " 'AIP:0000122',\n",
    " 'AIP:0000970',\n",
    " 'AIP:0000506',\n",
    " 'AIP:0003528',\n",
    " 'AIP:0100060']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_testset = [case for case in visual_qa_evaluator.filtered_qa_data if case['diagnosis_id'] in filtered_diagnosis_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_case = set()\n",
    "for case in filtered_testset:\n",
    "    main_case.add(case['case_id'].split('_')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(main_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions from model  0\n",
      " 9/10 [==========================>...] - ETA: 5s \n",
      "Processing remainder: 30\n"
     ]
    }
   ],
   "source": [
    "visual_diagnosis_ids = list(visual_qa_evaluator.visual_qa.visual_diagnosis_ids)\n",
    "labels = []\n",
    "image_paths = []\n",
    "for sample in filtered_testset:\n",
    "    image_paths.append(os.path.join(visual_data_dir, sample[\"image_id\"]))\n",
    "    labels.append(visual_diagnosis_ids.index(sample['diagnosis_id']))\n",
    "    \n",
    "probs = cnn_evaluator.predict(image_paths)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_result = cnn_evaluator.get_metrics(probs, labels, top_k=5, concept_labels=visual_qa_evaluator.visual_qa.visual_diagnosis_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "mode": "lines",
         "name": "all",
         "type": "scatter",
         "uid": "b0e6c86d-7096-48fe-8903-94cca6cee875",
         "x": [
          1,
          2,
          3,
          4,
          5
         ],
         "y": [
          0.4114286,
          0.5342857,
          0.6,
          0.6685714,
          0.7085714
         ]
        }
       ],
       "layout": {
        "xaxis": {
         "title": {
          "text": "Top-k"
         }
        },
        "yaxis": {
         "title": {
          "text": "Accuracy"
         }
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"f7c285db-82ac-465e-aaa5-5ec817fb65ba\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"f7c285db-82ac-465e-aaa5-5ec817fb65ba\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        'f7c285db-82ac-465e-aaa5-5ec817fb65ba',\n",
       "                        [{\"mode\": \"lines\", \"name\": \"all\", \"type\": \"scatter\", \"uid\": \"b0e6c86d-7096-48fe-8903-94cca6cee875\", \"x\": [1, 2, 3, 4, 5], \"y\": [0.4114286, 0.5342857, 0.6, 0.6685714, 0.7085714]}],\n",
       "                        {\"xaxis\": {\"title\": {\"text\": \"Top-k\"}}, \"yaxis\": {\"title\": {\"text\": \"Accuracy\"}}},\n",
       "                        {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('f7c285db-82ac-465e-aaa5-5ec817fb65ba');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn_evaluator.plot_top_k_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>accuracy_top_1</th>\n",
       "      <th>accuracy_top_2</th>\n",
       "      <th>accuracy_top_3</th>\n",
       "      <th>accuracy_top_4</th>\n",
       "      <th>accuracy_top_5</th>\n",
       "      <th>weighted_precision</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>number_of_samples</th>\n",
       "      <th>number_of_classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_max_acc_1gpu.h5</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.463</td>\n",
       "      <td>350</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id  accuracy_top_1  accuracy_top_2  accuracy_top_3  \\\n",
       "0  model_max_acc_1gpu.h5           0.411           0.534             0.6   \n",
       "\n",
       "   accuracy_top_4  accuracy_top_5  weighted_precision  sensitivity  precision  \\\n",
       "0           0.669           0.709               0.753        0.039      0.072   \n",
       "\n",
       "   f1_score  number_of_samples  number_of_classes  \n",
       "0     0.463                350                133  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_evaluator.show_results(mode='average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_qa_evaluator.filtered_qa_data = filtered_testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "combination_result = visual_qa_evaluator.evaluate(probs, differential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mode</th>\n",
       "      <th>top_1</th>\n",
       "      <th>top_2</th>\n",
       "      <th>top_3</th>\n",
       "      <th>top_4</th>\n",
       "      <th>top_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Visual</td>\n",
       "      <td>0.411429</td>\n",
       "      <td>0.534286</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.668571</td>\n",
       "      <td>0.708571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Visual_QA</td>\n",
       "      <td>0.317143</td>\n",
       "      <td>0.362857</td>\n",
       "      <td>0.391429</td>\n",
       "      <td>0.411429</td>\n",
       "      <td>0.437143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Mode     top_1     top_2     top_3     top_4     top_5\n",
       "0     Visual  0.411429  0.534286  0.600000  0.668571  0.708571\n",
       "1  Visual_QA  0.317143  0.362857  0.391429  0.411429  0.437143"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.compare_visual_by_definition_results(visual_result['average']['accuracy'] ,combination_result['average']['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
